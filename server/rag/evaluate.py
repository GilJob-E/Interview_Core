"""
RAG ì‹¤íš¨ì„± í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
Retrieval Qualityì™€ Generation Qualityë¥¼ ì¸¡ì •í•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ íš¨ê³¼ë¥¼ ê²€ì¦
"""
import json
import time
import random
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime

from dotenv import load_dotenv
load_dotenv()

# RAG ì‹œìŠ¤í…œ import
from rag import RAGSystem, index_exists
from rag.document_loader import load_interview_documents


@dataclass
class RetrievalMetrics:
    """ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ"""
    query: str
    expected_occupation: str
    expected_experience: str
    retrieved_docs: List[Dict]

    # Metrics
    occupation_match_rate: float  # ì§ì—…êµ° ì¼ì¹˜ìœ¨
    experience_match_rate: float  # ê²½ë ¥ ì¼ì¹˜ìœ¨
    avg_similarity_score: float   # í‰ê·  ìœ ì‚¬ë„ (ì¶”ì •)
    retrieval_time_ms: float      # ê²€ìƒ‰ ì‹œê°„


@dataclass
class GenerationMetrics:
    """ìƒì„± í’ˆì§ˆ ì§€í‘œ"""
    query: str
    response: str
    response_length: int
    generation_time_ms: float
    is_korean: bool              # í•œê¸€ ì‘ë‹µ ì—¬ë¶€
    is_question_format: bool     # ì§ˆë¬¸ í˜•íƒœì¸ì§€
    has_context_reference: bool  # ì»¨í…ìŠ¤íŠ¸ ì°¸ì¡° ì—¬ë¶€


@dataclass
class EvaluationResult:
    """ì „ì²´ í‰ê°€ ê²°ê³¼"""
    timestamp: str
    total_queries: int

    # Retrieval Quality
    avg_occupation_match: float
    avg_experience_match: float
    avg_retrieval_time_ms: float

    # Generation Quality
    avg_response_length: float
    avg_generation_time_ms: float
    korean_rate: float
    question_format_rate: float

    # Details
    retrieval_results: List[Dict]
    generation_results: List[Dict]


class RAGEvaluator:
    """RAG ì‹œìŠ¤í…œ í‰ê°€ê¸°"""

    def __init__(self, rag_system: Optional[RAGSystem] = None):
        """
        í‰ê°€ê¸° ì´ˆê¸°í™”

        Args:
            rag_system: í‰ê°€í•  RAG ì‹œìŠ¤í…œ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
        """
        if rag_system is None:
            if not index_exists():
                raise FileNotFoundError(
                    "Vector store index not found. "
                    "Run 'python -m rag.build_index' first."
                )
            self.rag = RAGSystem()
        else:
            self.rag = rag_system

    def create_test_queries(self, n_samples: int = 20) -> List[Dict]:
        """
        í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìƒì„±

        ë‹¤ì–‘í•œ ë©´ì ‘ ë‹µë³€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜
        """
        test_cases = [
            # ICT ê´€ë ¨
            {
                "query": "ì €ëŠ” 5ë…„ê°„ ë°±ì—”ë“œ ê°œë°œìë¡œ ì¼í•˜ë©´ì„œ Javaì™€ Springì„ ì£¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ìµœê·¼ì—ëŠ” MSA ì•„í‚¤í…ì²˜ ì „í™˜ í”„ë¡œì íŠ¸ë¥¼ ì£¼ë„í–ˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "ICT",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ì „ê³µì€ ì»´í“¨í„°ê³µí•™ì´ê³  ì¸í„´ ê²½í—˜ì€ ì—†ì§€ë§Œ ê°œì¸ í”„ë¡œì íŠ¸ë¡œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì–´ë´¤ìŠµë‹ˆë‹¤.",
                "expected_occupation": "ICT",
                "expected_experience": "NEW"
            },
            {
                "query": "ë°ì´í„° ë¶„ì„ ì—…ë¬´ë¥¼ ë‹´ë‹¹í–ˆê³  Pythonê³¼ SQLì„ í™œìš©í•´ì„œ ë¦¬í¬íŠ¸ë¥¼ ìë™í™”í–ˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "ICT",
                "expected_experience": "EXPERIENCED"
            },

            # ê²½ì˜/ê´€ë¦¬ ê´€ë ¨
            {
                "query": "íŒ€ ë¦¬ë”ë¡œì„œ 10ëª…ì˜ íŒ€ì›ì„ ê´€ë¦¬í–ˆê³  ë¶„ê¸°ë³„ ëª©í‘œ ë‹¬ì„±ë¥  120%ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ê²½ì˜í•™ì„ ì „ê³µí–ˆê³  í•™êµì—ì„œ ê²½ì˜ ë™ì•„ë¦¬ íšŒì¥ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "NEW"
            },
            {
                "query": "ì €ëŠ” ë¶€ì„œê°„ í˜‘ì—…ì„ ì´ëŒì–´ë‚¸ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ê°ˆë“± ìƒí™©ì—ì„œë„ ì¤‘ì¬ì ì—­í• ì„ ì˜ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "EXPERIENCED"
            },

            # ì˜ì—…/ë§ˆì¼€íŒ… ê´€ë ¨
            {
                "query": "ì˜ì—… ëª©í‘œë¥¼ 150% ë‹¬ì„±í–ˆê³  ì‹ ê·œ ê³ ê° 100ëª…ì„ ìœ ì¹˜í–ˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "SM",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ë§ˆì¼€íŒ… ê³µëª¨ì „ì—ì„œ ìˆ˜ìƒí•œ ê²½í—˜ì´ ìˆê³  SNS ë§ˆì¼€íŒ…ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.",
                "expected_occupation": "SM",
                "expected_experience": "NEW"
            },

            # ì—°êµ¬ê°œë°œ ê´€ë ¨
            {
                "query": "ì„ì‚¬ ê³¼ì •ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ë¥¼ í–ˆê³  ë…¼ë¬¸ 2í¸ì„ ê²Œì¬í–ˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "RND",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš°ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ê³  ì‹¤í—˜ì ì¸ í”„ë¡œì íŠ¸ë¥¼ ì¦ê¹ë‹ˆë‹¤.",
                "expected_occupation": "RND",
                "expected_experience": "NEW"
            },

            # ì¼ë°˜ì ì¸ ë‹µë³€ë“¤
            {
                "query": "ì œ ê°•ì ì€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìì™€ ì†Œí†µí•˜ëŠ” ê²ƒì„ ì˜í•©ë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ì €ëŠ” ë¬¸ì œê°€ ìƒê¸°ë©´ í¬ê¸°í•˜ì§€ ì•Šê³  ëê¹Œì§€ í•´ê²°í•˜ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤.",
                "expected_occupation": "ICT",
                "expected_experience": "NEW"
            },
            {
                "query": "ì´ íšŒì‚¬ì— ì§€ì›í•œ ì´ìœ ëŠ” ì„±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ìƒê°í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "NEW"
            },
            {
                "query": "5ë…„ í›„ì—ëŠ” íŒ€ì„ ì´ë„ëŠ” ë¦¬ë”ê°€ ë˜ì–´ ìˆê³  ì‹¶ìŠµë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ì €ëŠ” ì•¼ê·¼ë„ ê¸°êº¼ì´ í•  ìˆ˜ ìˆê³  ì£¼ë§ ì¶œê·¼ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "expected_occupation": "SM",
                "expected_experience": "NEW"
            },

            # ì‹¤íŒ¨/ì–´ë ¤ì›€ ê²½í—˜
            {
                "query": "í”„ë¡œì íŠ¸ê°€ ì‹¤íŒ¨í–ˆì„ ë•Œ ì›ì¸ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒì—ëŠ” ê°™ì€ ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "expected_occupation": "ICT",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "íŒ€ì›ê³¼ ê°ˆë“±ì´ ìˆì—ˆì§€ë§Œ ëŒ€í™”ë¥¼ í†µí•´ í•´ê²°í–ˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "EXPERIENCED"
            },

            # ì§ë¬´ ì í•©ì„±
            {
                "query": "ì´ ì§ë¬´ì— í•„ìš”í•œ ì—­ëŸ‰ì„ ê°–ì¶”ê¸° ìœ„í•´ ìê²©ì¦ì„ ì·¨ë“í•˜ê³  ê´€ë ¨ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤.",
                "expected_occupation": "ICT",
                "expected_experience": "NEW"
            },
            {
                "query": "ì €ëŠ” ê³ ê° ì‘ëŒ€ ê²½í—˜ì´ í’ë¶€í•˜ê³  CS ë§Œì¡±ë„ 1ìœ„ë¥¼ ë‹¬ì„±í•œ ì ì´ ìˆìŠµë‹ˆë‹¤.",
                "expected_occupation": "SM",
                "expected_experience": "EXPERIENCED"
            },
            {
                "query": "ì œê°€ ë§¡ì€ ì—…ë¬´ëŠ” í•­ìƒ ê¸°í•œ ë‚´ì— ì™„ë£Œí–ˆê³  í’ˆì§ˆë„ ì¢‹ë‹¤ëŠ” í‰ê°€ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.",
                "expected_occupation": "BM",
                "expected_experience": "EXPERIENCED"
            },
        ]

        # ìƒ˜í”Œë§
        if n_samples < len(test_cases):
            return random.sample(test_cases, n_samples)
        return test_cases

    def evaluate_retrieval(
        self,
        query: str,
        expected_occupation: str,
        expected_experience: str,
        k: int = 3
    ) -> RetrievalMetrics:
        """
        ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€

        Args:
            query: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
            expected_occupation: ê¸°ëŒ€í•˜ëŠ” ì§ì—…êµ°
            expected_experience: ê¸°ëŒ€í•˜ëŠ” ê²½ë ¥
            k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜

        Returns:
            RetrievalMetrics: ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ
        """
        start_time = time.time()

        # ê²€ìƒ‰ ìˆ˜í–‰
        results = self.rag.retrieve(query, k=k)

        retrieval_time = (time.time() - start_time) * 1000  # ms

        # ì¼ì¹˜ìœ¨ ê³„ì‚°
        occupation_matches = sum(
            1 for r in results
            if r.get("occupation", "").upper() == expected_occupation.upper()
        )
        experience_matches = sum(
            1 for r in results
            if r.get("experience", "").upper() == expected_experience.upper()
        )

        occupation_match_rate = occupation_matches / len(results) if results else 0
        experience_match_rate = experience_matches / len(results) if results else 0

        return RetrievalMetrics(
            query=query,
            expected_occupation=expected_occupation,
            expected_experience=expected_experience,
            retrieved_docs=results,
            occupation_match_rate=occupation_match_rate,
            experience_match_rate=experience_match_rate,
            avg_similarity_score=0.0,  # FAISSëŠ” ì§ì ‘ ìŠ¤ì½”ì–´ ë°˜í™˜ ì•ˆí•¨
            retrieval_time_ms=retrieval_time
        )

    def evaluate_generation(
        self,
        query: str,
        occupation: Optional[str] = None,
        experience: Optional[str] = None
    ) -> GenerationMetrics:
        """
        ìƒì„± í’ˆì§ˆ í‰ê°€

        Args:
            query: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
            occupation: ì§ì—…êµ° í•„í„°
            experience: ê²½ë ¥ í•„í„°

        Returns:
            GenerationMetrics: ìƒì„± í’ˆì§ˆ ì§€í‘œ
        """
        start_time = time.time()

        # ì‘ë‹µ ìƒì„±
        response = self.rag.generate(query, occupation, experience)

        generation_time = (time.time() - start_time) * 1000  # ms

        # í’ˆì§ˆ ì²´í¬
        is_korean = any('\uac00' <= c <= '\ud7a3' for c in response)  # í•œê¸€ í¬í•¨
        is_question = response.strip().endswith("?") or "?" in response
        has_context = any(
            keyword in response.lower()
            for keyword in ["ë‹µë³€", "ê²½í—˜", "ë§ì”€", "ì§ˆë¬¸", "ì–´ë–»ê²Œ", "ì™œ"]
        )

        return GenerationMetrics(
            query=query,
            response=response,
            response_length=len(response),
            generation_time_ms=generation_time,
            is_korean=is_korean,
            is_question_format=is_question,
            has_context_reference=has_context
        )

    def run_evaluation(
        self,
        n_samples: int = 10,
        include_generation: bool = True,
        save_results: bool = True,
        output_dir: Optional[Path] = None
    ) -> EvaluationResult:
        """
        ì „ì²´ í‰ê°€ ì‹¤í–‰

        Args:
            n_samples: í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜
            include_generation: ìƒì„± í‰ê°€ í¬í•¨ ì—¬ë¶€
            save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬

        Returns:
            EvaluationResult: ì „ì²´ í‰ê°€ ê²°ê³¼
        """
        print(f"\n{'='*60}")
        print(f"RAG ì‹¤íš¨ì„± í‰ê°€ ì‹œì‘ (ìƒ˜í”Œ ìˆ˜: {n_samples})")
        print(f"{'='*60}\n")

        test_queries = self.create_test_queries(n_samples)

        retrieval_results = []
        generation_results = []

        # ê²€ìƒ‰ í‰ê°€
        print("[1/2] ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ì¤‘...")
        for i, tc in enumerate(test_queries):
            print(f"  [{i+1}/{len(test_queries)}] {tc['query'][:40]}...")

            metrics = self.evaluate_retrieval(
                tc["query"],
                tc["expected_occupation"],
                tc["expected_experience"]
            )
            retrieval_results.append(asdict(metrics))

        # ìƒì„± í‰ê°€
        if include_generation:
            print("\n[2/2] ìƒì„± í’ˆì§ˆ í‰ê°€ ì¤‘...")
            for i, tc in enumerate(test_queries):
                print(f"  [{i+1}/{len(test_queries)}] {tc['query'][:40]}...")

                metrics = self.evaluate_generation(tc["query"])
                generation_results.append(asdict(metrics))

        # ì§‘ê³„
        avg_occupation_match = sum(
            r["occupation_match_rate"] for r in retrieval_results
        ) / len(retrieval_results)

        avg_experience_match = sum(
            r["experience_match_rate"] for r in retrieval_results
        ) / len(retrieval_results)

        avg_retrieval_time = sum(
            r["retrieval_time_ms"] for r in retrieval_results
        ) / len(retrieval_results)

        if generation_results:
            avg_response_length = sum(
                r["response_length"] for r in generation_results
            ) / len(generation_results)

            avg_generation_time = sum(
                r["generation_time_ms"] for r in generation_results
            ) / len(generation_results)

            korean_rate = sum(
                1 for r in generation_results if r["is_korean"]
            ) / len(generation_results)

            question_format_rate = sum(
                1 for r in generation_results if r["is_question_format"]
            ) / len(generation_results)
        else:
            avg_response_length = 0
            avg_generation_time = 0
            korean_rate = 0
            question_format_rate = 0

        result = EvaluationResult(
            timestamp=datetime.now().isoformat(),
            total_queries=len(test_queries),
            avg_occupation_match=avg_occupation_match,
            avg_experience_match=avg_experience_match,
            avg_retrieval_time_ms=avg_retrieval_time,
            avg_response_length=avg_response_length,
            avg_generation_time_ms=avg_generation_time,
            korean_rate=korean_rate,
            question_format_rate=question_format_rate,
            retrieval_results=retrieval_results,
            generation_results=generation_results
        )

        # ê²°ê³¼ ì¶œë ¥
        self._print_summary(result)

        # ê²°ê³¼ ì €ì¥
        if save_results:
            self._save_results(result, output_dir)

        return result

    def _print_summary(self, result: EvaluationResult):
        """í‰ê°€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print("ğŸ“Š RAG ì‹¤íš¨ì„± í‰ê°€ ê²°ê³¼")
        print(f"{'='*60}")

        print(f"\nğŸ“‹ ê¸°ë³¸ ì •ë³´:")
        print(f"  - í‰ê°€ ì‹œê°„: {result.timestamp}")
        print(f"  - í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: {result.total_queries}")

        print(f"\nğŸ” ê²€ìƒ‰ í’ˆì§ˆ (Retrieval Quality):")
        print(f"  - ì§ì—…êµ° ì¼ì¹˜ìœ¨: {result.avg_occupation_match*100:.1f}%")
        print(f"  - ê²½ë ¥ ì¼ì¹˜ìœ¨: {result.avg_experience_match*100:.1f}%")
        print(f"  - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {result.avg_retrieval_time_ms:.1f}ms")

        if result.generation_results:
            print(f"\nâœï¸ ìƒì„± í’ˆì§ˆ (Generation Quality):")
            print(f"  - í‰ê·  ì‘ë‹µ ê¸¸ì´: {result.avg_response_length:.0f}ì")
            print(f"  - í‰ê·  ìƒì„± ì‹œê°„: {result.avg_generation_time_ms:.1f}ms")
            print(f"  - í•œê¸€ ì‘ë‹µ ë¹„ìœ¨: {result.korean_rate*100:.1f}%")
            print(f"  - ì§ˆë¬¸ í˜•ì‹ ë¹„ìœ¨: {result.question_format_rate*100:.1f}%")

        # ì‹¤íš¨ì„± íŒì •
        print(f"\n{'='*60}")
        print("ğŸ“ˆ RAG ì‹¤íš¨ì„± íŒì •:")

        retrieval_score = (result.avg_occupation_match + result.avg_experience_match) / 2

        if retrieval_score >= 0.5:
            print("  âœ… ê²€ìƒ‰ í’ˆì§ˆ: ì–‘í˜¸ (ê´€ë ¨ ë¬¸ì„œë¥¼ ì˜ ì°¾ê³  ìˆìŒ)")
        elif retrieval_score >= 0.3:
            print("  âš ï¸ ê²€ìƒ‰ í’ˆì§ˆ: ë³´í†µ (ì¼ë¶€ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ìŒ)")
        else:
            print("  âŒ ê²€ìƒ‰ í’ˆì§ˆ: ê°œì„  í•„ìš” (ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ì´ ë¶€ì¡±í•¨)")

        if result.korean_rate >= 0.9 and result.question_format_rate >= 0.5:
            print("  âœ… ìƒì„± í’ˆì§ˆ: ì–‘í˜¸ (ë©´ì ‘ê´€ ì—­í•  ìˆ˜í–‰ ì¤‘)")
        elif result.korean_rate >= 0.7:
            print("  âš ï¸ ìƒì„± í’ˆì§ˆ: ë³´í†µ (ì¼ë¶€ ê°œì„  í•„ìš”)")
        else:
            print("  âŒ ìƒì„± í’ˆì§ˆ: ê°œì„  í•„ìš”")

        print(f"{'='*60}\n")

    def _save_results(
        self,
        result: EvaluationResult,
        output_dir: Optional[Path] = None
    ):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        if output_dir is None:
            output_dir = Path(__file__).parent / "evaluation_results"

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"evaluation_{timestamp}.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(result), f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_file}")


def run_quick_test():
    """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (3ê°œ ìƒ˜í”Œ)"""
    evaluator = RAGEvaluator()
    return evaluator.run_evaluation(n_samples=3, include_generation=True)


def run_full_evaluation():
    """ì „ì²´ í‰ê°€ (20ê°œ ìƒ˜í”Œ)"""
    evaluator = RAGEvaluator()
    return evaluator.run_evaluation(n_samples=20, include_generation=True)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="RAG ì‹¤íš¨ì„± í‰ê°€")
    parser.add_argument(
        "--samples", "-n",
        type=int,
        default=10,
        help="í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸: 10)"
    )
    parser.add_argument(
        "--quick", "-q",
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (3ê°œ ìƒ˜í”Œ)"
    )
    parser.add_argument(
        "--no-generation",
        action="store_true",
        help="ìƒì„± í‰ê°€ ì œì™¸ (ê²€ìƒ‰ë§Œ í‰ê°€)"
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="ê²°ê³¼ ì €ì¥ ì•ˆ í•¨"
    )

    args = parser.parse_args()

    if args.quick:
        run_quick_test()
    else:
        evaluator = RAGEvaluator()
        evaluator.run_evaluation(
            n_samples=args.samples,
            include_generation=not args.no_generation,
            save_results=not args.no_save
        )
