import os
import io
import json  # [New] JSON ë°ì´í„° ì²˜ë¦¬ìš©
import numpy as np
import soundfile as sf
from groq import Groq
from elevenlabs.client import ElevenLabs
from dotenv import load_dotenv

load_dotenv()

class AIOrchestrator:
    def __init__(self):
        print("[System] Initializing AI Models (Cloud API Mode)...")
        
        # 1. STT
        print("[STT] Using Groq Whisper API.")

        # 2. LLM & STT Client
        self.groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        print("[LLM/STT] Groq Client Connected.")

        # 3. TTS
        self.tts_client = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))
        print("[TTS] ElevenLabs Client Connected.")

    def transcribe_audio(self, audio_data: np.ndarray):
        try:
            max_val = np.max(np.abs(audio_data))
            if max_val > 0: audio_data = audio_data / max_val

            buffer = io.BytesIO()
            sf.write(buffer, audio_data, 16000, format='WAV', subtype='PCM_16')
            buffer.seek(0) 
            
            transcription = self.groq_client.audio.transcriptions.create(
                file=("input.wav", buffer),
                model="whisper-large-v3",
                language="ko",
                temperature=0.0,
                response_format="json"
            )
            
            text = transcription.text.strip()
            # print(f"[Debug] Groq Whisper Output: '{text}'")

            hallucinations = [
                "Thank you for watching", "MBC News", "ìë§‰ ì œê³µ", 
                "ì‹œì²­í•´ì£¼ì…”ì„œ", "ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤", "Unidentified", "ê°ì‚¬í•©ë‹ˆë‹¤",
            ]
            if any(h.lower() in text.lower() for h in hallucinations):
                return ""
            if len(text) < 1: return ""
                
            return text

        except Exception as e:
            print(f"[STT API Error] {e}")
            return ""

    def is_sentence_complete(self, text: str) -> bool:
        if not text: return False
        text = text.strip()
        short_phrases = ["ë„¤", "ì•„ë‹ˆìš”", "ì•ˆë…•í•˜ì„¸ìš”", "ë°˜ê°‘ìŠµë‹ˆë‹¤", "ê·¸ë ‡ìŠµë‹ˆë‹¤", "ë§ìŠµë‹ˆë‹¤"]
        if text in short_phrases: return True
        connective_endings = ["ê³ .", "ëŠ”ë°.", "ì§€ë§Œ.", "ì„œ.", "ë©°.", "ë©´ì„œ.", "ê³ ìš”.", "êµ¬ìš”."]
        for ending in connective_endings:
            if text.endswith(ending): return False
        definitive_endings = ["ë‹¤.", "ì£ .", "ê¹Œ.", "ì•¼.", "í•´.", "?", "!"]
        for ending in definitive_endings:
            if text.endswith(ending): return True
        return False

    def generate_llm_response(self, user_text: str):
        # LLM1: ë©´ì ‘ê´€ (ì§ˆë¬¸ ë° ëŒ€í™” ì§„í–‰)
        model_id = "llama-3.3-70b-versatile" 
        system_prompt = (
            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ì§€ë§Œ ë‚ ì¹´ë¡œìš´ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. "
            "ì§€ì›ìì˜ ë‹µë³€ì„ ë“£ê³  ê¼¬ë¦¬ì§ˆë¬¸ì„ í•˜ê±°ë‚˜ í•œêµ­ì–´ë¡œ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”. "
            "ë‹µë³€ì€ êµ¬ì–´ì²´ë¡œ ì§§ê³  ê°„ê²°í•˜ê²Œ(2~3ë¬¸ì¥ ì´ë‚´) í•˜ì„¸ìš”."
        )
        return self.groq_client.chat.completions.create(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text},
            ],
            model=model_id,
            stream=True 
        )

    # =========================================================================
    # [New] LLM2: ë©´ì ‘ ì½”ì¹˜ (ì‹¤ì‹œê°„ í”¼ë“œë°± & ìµœì¢… í‰ê°€)
    # =========================================================================

    async def generate_instant_feedback(self, user_text: str, analysis_result: dict):
        """
        [LLM2] í„´ë³„ ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„± (Z-Score ê¸°ë°˜ ì •ë°€ ë¶„ì„)
        """
        try:
            # 1. ë°ì´í„° ì¶”ì¶œ (ëª¨ë“  í”¼ì³ í™•ë³´)
            features = analysis_result.get("multimodal_features", {})
            
            # (A) Audio Features
            audio = features.get("audio", {})
            pitch = audio.get("pitch", {})
            intensity = audio.get("intensity", {})
            pause = audio.get("pause_duration", {})
            
            # (B) Video Features
            video = features.get("video", {})
            eye = video.get("eye_contact", {})
            smile = video.get("smile", {})
            nod = video.get("head_nod", {})
            
            # (C) Text Features
            text_feat = features.get("text", {})
            speed = text_feat.get("wpsec", {})
            fillers = text_feat.get("fillers", {})
            diversity = text_feat.get("upsec", {})

            # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í†µê³„ í•´ì„ ê°€ì´ë“œ)
            system_prompt = """
            ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ì˜ 'AI ë©´ì ‘ ì½”ì¹˜'ì…ë‹ˆë‹¤. 
            ì§€ì›ìì˜ [ë‹µë³€]ê³¼ [ë©€í‹°ëª¨ë‹¬ ë°ì´í„°]ë¥¼ ë¶„ì„í•˜ì—¬, ì¦‰ì‹œ êµì •í•´ì•¼ í•  ì ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ì¡°ì–¸í•˜ì„¸ìš”.

            [ë°ì´í„° í•´ì„ ê°€ì´ë“œ (ì¤‘ìš”)]
            ì œê³µë˜ëŠ” ìˆ˜ì¹˜ëŠ” Z-Score(í‘œì¤€ì ìˆ˜)ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. Z-Scoreê°€ Â±1.0ì„ ë²—ì–´ë‚˜ë©´ 'í‰ê· ê³¼ ë‹¤ë¦„'ì„ ì˜ë¯¸í•˜ë¯€ë¡œ ì£¼ì˜ ê¹Šê²Œ ë³´ì‹­ì‹œì˜¤.
            
            1. ì˜¤ë””ì˜¤ (Audio)
            - Pitch (ìŒë†’ì´): Z > 1.5 (ë„ˆë¬´ ë†’ìŒ/ê¸´ì¥), Z < -1.5 (ë„ˆë¬´ ë‚®ìŒ/ì¹¨ìš¸)
            - Intensity (ìŒëŸ‰): Z < -1.0 (ëª©ì†Œë¦¬ ì‘ìŒ/ìì‹ ê° ë¶€ì¡±)
            -Pause (ì¹¨ë¬µ): Z > 1.5 (ë‹µë³€ ì§€ì—°/ë‹µë‹µí•¨) 

            2. ë¹„ì „ (Video)
            - Eye Contact (ì‹œì„ ): Z < -1.0 (ì‹œì„  íšŒí”¼/ë¶ˆì•ˆ), ë¹„ìœ¨ 0.6 ë¯¸ë§Œì€ ê²½ê³  ëŒ€ìƒ.
            - Smile (í‘œì •): Z < -1.0 (í‘œì • êµ³ìŒ), ì ì ˆí•œ ë¯¸ì†ŒëŠ” ê¸ì •ì .
            - Nod (ë„ë•ì„): ê²½ì²­ íƒœë„ ì§€í‘œ. (ë°œí™” ì¤‘ì—ëŠ” ê°•ì¡° ì œìŠ¤ì²˜ë¡œ í•´ì„)

            3. í…ìŠ¤íŠ¸ (Text)
            - Speed (ì†ë„): Z > 1.5 (ë„ˆë¬´ ë¹ ë¦„), Z < -1.5 (ë„ˆë¬´ ëŠë¦¼)
            - Fillers (ì¶”ì„ìƒˆ): "ìŒ, ì–´, ê·¸" ë¹ˆë„. Z > 1.0ì´ë©´ ì§€ì  í•„ìš”.
            - Diversity (ì–´íœ˜ ë‹¤ì–‘ì„±): ë‚®ìœ¼ë©´ ë‹¨ì¡°ë¡œìš´ í‘œí˜„ ë°˜ë³µ.

            [ì‘ì„± ê·œì¹™]
            - Z-Scoreê°€ íŠ€ëŠ” í•­ëª©(Â±1.5 ì´ìƒ)ì„ ìš°ì„ ì ìœ¼ë¡œ ì§€ì í•˜ì„¸ìš”.
            - ëª¨ë“  ìˆ˜ì¹˜ê°€ ì •ìƒ ë²”ìœ„ë¼ë©´ "íƒœë„ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤. ì§€ê¸ˆì²˜ëŸ¼ ë‹µë³€í•˜ì„¸ìš”."ë¼ê³  ì¹­ì°¬í•˜ì„¸ìš”.
            - ë§íˆ¬ëŠ” "í•´ìš”ì²´"ë¡œ ì •ì¤‘í•˜ì§€ë§Œ ë‹¨í˜¸í•˜ê²Œ ì½”ì¹­í•˜ì„¸ìš”.
            """
            
            # 3. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ë°ì´í„° ì£¼ì…)
            user_prompt = f"""
            [ì§€ì›ì ë‹µë³€]: "{user_text}"
            
            [ë¶„ì„ ë°ì´í„°]
            1. Audio
            - Pitch: {pitch.get('value', 0)}Hz (Z: {pitch.get('z_score', 0)})
            - Volume: {intensity.get('value', 0)}dB (Z: {intensity.get('z_score', 0)})
            - Pause: {pause.get('value', 0)}s (Z: {pause.get('z_score', 0)})
            
            2. Video
            - Eye Contact: {eye.get('value', 0)} (Z: {eye.get('z_score', 0)})
            - Smile: {smile.get('value', 0)} (Z: {smile.get('z_score', 0)})
            - Nods: {nod.get('value', 0)} times
            
            3. Text
            - Speed: {speed.get('value', 0)} wps (Z: {speed.get('z_score', 0)})
            - Fillers: {fillers.get('value', 0)} count/sec (Z: {fillers.get('z_score', 0)})
            - Vocabulary: {diversity.get('value', 0)} ups (Z: {diversity.get('z_score', 0)})
            """

            # 4. LLM í˜¸ì¶œ
            response = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                model="llama-3.3-70b-versatile",
                temperature=0.6,
                max_tokens=150
            )
            
            return response.choices[0].message.content

        except Exception as e:
            print(f"[Coach Error] {e}")
            return "í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    async def generate_final_report(self, interview_history: list):
        """
        [LLM2] ë©´ì ‘ ì¢…ë£Œ í›„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        - ì…ë ¥: ì „ì²´ ëŒ€í™” ê¸°ë¡ ë° í„´ë³„ ë¶„ì„ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        - ì¶œë ¥: ë§ˆí¬ë‹¤ìš´ í˜•íƒœì˜ ì¢…í•© í‰ê°€ì„œ
        """
        try:
            # íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            history_text = ""
            for turn in interview_history:
                history_text += f"""
                [Turn {turn['turn_id']}]
                User: {turn['user_text']}
                AI: {turn['ai_text']}
                Stats: {json.dumps(turn['stats'])}
                Coach Feedback: {turn['coach_feedback']}
                ------------------------------------------------
                """

            system_prompt = """
            ë‹¹ì‹ ì€ ë² í…Œë‘ 'ë©´ì ‘ ì „ë¬¸ ì½”ì¹˜'ì…ë‹ˆë‹¤.
            ì „ì²´ ë©´ì ‘ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, ì§€ì›ìì—ê²Œ ë„ì›€ì´ ë˜ëŠ” [ìµœì¢… ë¶„ì„ ë¦¬í¬íŠ¸]ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
            
            [ì‘ì„± ì–‘ì‹ (Markdown)]
            # ğŸ“Š ë©´ì ‘ ì¢…í•© ë¦¬í¬íŠ¸
            
            ## 1. ì´í‰ (100ì  ë§Œì  ì ìˆ˜ í¬í•¨)
            - ì „ì²´ì ì¸ ì¸ìƒê³¼ ì ìˆ˜
            
            ## 2. ê°•ì  (Good Points)
            - ë°ì´í„°ì— ê¸°ë°˜í•œ ì¹­ì°¬ (ì˜ˆ: ì‹œì„  ì²˜ë¦¬ê°€ ì•ˆì •ì ì„, ëª©ì†Œë¦¬ í†¤ì´ ì‹ ë¢°ê° ìˆìŒ)
            
            ## 3. ê°œì„ í•  ì  (Weak Points)
            - êµ¬ì²´ì ì¸ ë°ì´í„° ê·¼ê±° (ì˜ˆ: Turn 3ì—ì„œ ë§ì´ ë¹¨ë¼ì§, ë‹µë³€ì´ ë‘ì„œì—†ìŒ)
            
            ## 4. Action Plan
            - ë‹¤ìŒ ë©´ì ‘ì„ ìœ„í•´ êµ¬ì²´ì ìœ¼ë¡œ ì—°ìŠµí•´ì•¼ í•  ì 
            """

            response = self.groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": history_text},
                ],
                model="llama-3.3-70b-versatile",
                temperature=0.6,
                max_tokens=1000 
            )
            
            return response.choices[0].message.content

        except Exception as e:
            print(f"[Report Error] {e}")
            return "ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    def text_to_speech_stream(self, text: str):
        if not text or not isinstance(text, str) or len(text.strip()) == 0:
            return []
        try:
            audio_stream = self.tts_client.text_to_speech.convert(
                voice_id="JBFqnCBsd6RMkjVDRZzb",
                output_format="pcm_16000", 
                text=text,
                model_id="eleven_turbo_v2_5"
            )
            return audio_stream
        except: return []