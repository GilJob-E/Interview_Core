# RAG (Retrieval Augmented Generation) System

ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ LangChain ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ë¬¸ì„œ

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG Pipeline                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  User Input (ë©´ì ‘ ë‹µë³€)                                      â”‚
â”‚       â”‚                                                     â”‚
â”‚       â–¼                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Embedding  â”‚â”€â”€â”€â–¶â”‚  FAISS Vector Store             â”‚    â”‚
â”‚  â”‚  (384-dim)  â”‚    â”‚  - 68,074 interview Q&A docs    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - index.faiss (100MB)          â”‚    â”‚
â”‚                     â”‚  - index.pkl (152MB)            â”‚    â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                     â”‚                       â”‚
â”‚                                     â–¼                       â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                          â”‚ Top-K Retrieval â”‚               â”‚
â”‚                          â”‚    (k=3~5)      â”‚               â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Prompt Template                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ System: ë©´ì ‘ê´€ ì—­í•  + ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ Human: {user_input}                        â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                     â”‚    Groq LLM         â”‚               â”‚
â”‚                     â”‚ (Llama-3.3-70b)     â”‚               â”‚
â”‚                     â”‚   Streaming Output  â”‚               â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Module Structure

```
server/rag/
â”œâ”€â”€ __init__.py         # RAGSystem í´ë˜ìŠ¤ (ë©”ì¸ ì¸í„°í˜ì´ìŠ¤)
â”œâ”€â”€ document_loader.py  # JSON â†’ LangChain Document ë³€í™˜
â”œâ”€â”€ vectorstore.py      # FAISS ë²¡í„°ìŠ¤í† ì–´ ê´€ë¦¬
â”œâ”€â”€ chain.py            # LangChain LCEL ì²´ì¸ êµ¬ì„±
â””â”€â”€ build_index.py      # CLI ì¸ë±ìŠ¤ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
```

### Components

| ëª¨ë“ˆ | ì—­í•  | í•µì‹¬ í•¨ìˆ˜ |
|------|------|----------|
| `document_loader.py` | JSON ë°ì´í„° â†’ Document ë³€í™˜ | `load_interview_documents()` |
| `vectorstore.py` | FAISS ì¸ë±ìŠ¤ ìƒì„±/ì €ì¥/ë¡œë“œ | `create_vectorstore()`, `load_vectorstore()` |
| `chain.py` | RAG ì²´ì¸ êµ¬ì„± (LCEL) | `create_rag_chain()`, `stream_response()` |
| `__init__.py` | í†µí•© ì¸í„°í˜ì´ìŠ¤ | `RAGSystem`, `get_rag_system()` |

## Tech Stack

| Component | Technology | Version |
|-----------|------------|---------|
| **Framework** | LangChain | 0.3.x |
| **Vector Store** | FAISS (CPU) | latest |
| **Embeddings** | HuggingFace `paraphrase-multilingual-MiniLM-L12-v2` | - |
| **LLM** | Groq API (Llama-3.3-70b-versatile) | - |

## Installation

```bash
pip install langchain langchain-community langchain-groq langchain-huggingface faiss-cpu sentence-transformers
```

## Usage

### Basic Usage

```python
from rag import RAGSystem

# ì´ˆê¸°í™”
rag = RAGSystem()

# ì‘ë‹µ ìƒì„±
response = rag.generate("ì €ëŠ” í”„ë¡œì íŠ¸ì—ì„œ íŒ€ì¥ ì—­í• ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤.")
print(response)
```

### Streaming

```python
from rag import RAGSystem

rag = RAGSystem()

# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
for chunk in rag.stream("ì €ëŠ” 3ë…„ê°„ ë°±ì—”ë“œ ê°œë°œì„ í–ˆìŠµë‹ˆë‹¤."):
    print(chunk, end="", flush=True)
```

### Filtering by Metadata

```python
from rag import RAGSystem

rag = RAGSystem()

# ICT ê²½ë ¥ì§ ë°ì´í„°ë§Œ ì°¸ì¡°
response = rag.generate(
    "í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.",
    occupation="ICT",
    experience="EXPERIENCED"
)
```

### Singleton Instance

```python
from rag import get_rag_system

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (ì„œë²„ í™˜ê²½)
rag = get_rag_system()
response = rag.generate("...")
```

### Direct Retrieval (ê²€ìƒ‰ë§Œ)

```python
from rag import RAGSystem

rag = RAGSystem()

# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ (LLM í˜¸ì¶œ ì—†ì´)
results = rag.retrieve("í”„ë¡œì íŠ¸ ê²½í—˜", k=5)
for r in results:
    print(f"Q: {r['question']}")
    print(f"   ({r['occupation']}/{r['experience']})")
```

## Building Index

### Prerequisites
- í•™ìŠµ ë°ì´í„°: `test_data/Training/**/*.json` (68,000+ files)
- í™˜ê²½ ë³€ìˆ˜: `.env`ì— `GROQ_API_KEY` ì„¤ì •

### Build Command

```bash
cd Interview_Core/server

# ì „ì²´ ë¹Œë“œ (ì•½ 16ë¶„ ì†Œìš”)
python -m rag.build_index

# í…ŒìŠ¤íŠ¸ ë¹Œë“œ (100ê°œë§Œ)
python -m rag.build_index --limit 100

# ì»¤ìŠ¤í…€ ê²½ë¡œ ì§€ì •
python -m rag.build_index --data-dir /path/to/data --output-dir /path/to/output
```

### Output
```
data/vectorstore/
â”œâ”€â”€ index.faiss  (100MB) - ë²¡í„° ì¸ë±ìŠ¤
â””â”€â”€ index.pkl    (152MB) - ë©”íƒ€ë°ì´í„°
```

## Configuration

### RAGSystem Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `index_path` | `data/vectorstore/` | ë²¡í„° ì¸ë±ìŠ¤ ê²½ë¡œ |
| `k` | `3` | ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜ |
| `model` | `llama-3.3-70b-versatile` | Groq LLM ëª¨ë¸ |
| `temperature` | `0.7` | LLM temperature |

### Embeddings

```python
# vectorstore.py
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# CPU ì„¤ì • (Mac í˜¸í™˜)
model_kwargs={'device': 'cpu'}
```

### Environment Variables

```bash
# .env
GROQ_API_KEY=your_groq_api_key
```

## Data Schema

### Input JSON Structure (Training Data)
```json
{
  "dataSet": {
    "info": {
      "occupation": "ICT",
      "experience": "EXPERIENCED",
      "gender": "M"
    },
    "question": {
      "raw": { "text": "ì§ˆë¬¸ í…ìŠ¤íŠ¸" }
    },
    "answer": {
      "raw": { "text": "ë‹µë³€ í…ìŠ¤íŠ¸" },
      "summary": { "text": "ë‹µë³€ ìš”ì•½" }
    }
  }
}
```

### Occupation Categories
| Code | Description |
|------|-------------|
| BM | Management |
| SM | Sales & Marketing |
| PS | Public Service |
| RND | Research & Development |
| ICT | Information Technology |
| ARD | Design & Architecture |
| MM | Manufacturing |

### Experience Levels
| Code | Description |
|------|-------------|
| EXPERIENCED | ê²½ë ¥ì§ (5ë…„ ì´ìƒ) |
| NEW | ì‹ ì… |

## Performance

| Metric | Value |
|--------|-------|
| Index Build Time | ~16 min (68K docs) |
| Documents Indexed | 68,074 |
| Index Size | 252 MB |
| Query Latency | < 500ms |
| Embedding Dimension | 384 |

## Evaluation System

RAG ì‹œìŠ¤í…œì˜ ì‹¤íš¨ì„±ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë„êµ¬

### Module Structure

```
server/rag/
â”œâ”€â”€ evaluate.py           # í‰ê°€ ì‹œìŠ¤í…œ ë©”ì¸
â””â”€â”€ evaluation_results/   # í‰ê°€ ê²°ê³¼ JSON ì €ì¥ (gitignore)
```

### Metrics

#### Retrieval Metrics (ê²€ìƒ‰ í’ˆì§ˆ)
| Metric | Description |
|--------|-------------|
| `occupation_match_rate` | ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì§ì—…êµ° ì¼ì¹˜ìœ¨ |
| `experience_match_rate` | ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ê²½ë ¥ ì¼ì¹˜ìœ¨ |
| `retrieval_time_ms` | ê²€ìƒ‰ ì†Œìš” ì‹œê°„ (ms) |

#### Generation Metrics (ìƒì„± í’ˆì§ˆ)
| Metric | Description |
|--------|-------------|
| `response_length` | ì‘ë‹µ ê¸¸ì´ (characters) |
| `generation_time_ms` | ìƒì„± ì†Œìš” ì‹œê°„ (ms) |
| `is_korean` | í•œêµ­ì–´ ì‘ë‹µ ì—¬ë¶€ |
| `is_question_format` | ì§ˆë¬¸ í˜•ì‹ ì—¬ë¶€ (ê¼¬ë¦¬ì§ˆë¬¸) |

### Usage

```bash
cd Interview_Core/server

# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (3ê°œ ìƒ˜í”Œ)
python -m rag.evaluate --quick

# ì „ì²´ í‰ê°€ (10ê°œ ìƒ˜í”Œ)
python -m rag.evaluate --samples 10

# ê²€ìƒ‰ë§Œ í‰ê°€ (ìƒì„± ì œì™¸)
python -m rag.evaluate --no-generation

# ê²°ê³¼ ì €ì¥ ì•ˆí•¨
python -m rag.evaluate --quick --no-save
```

### CLI Options

| Option | Short | Default | Description |
|--------|-------|---------|-------------|
| `--samples` | `-n` | 10 | í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜ |
| `--quick` | `-q` | - | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (3ê°œ ìƒ˜í”Œ) |
| `--no-generation` | - | - | ìƒì„± í‰ê°€ ê±´ë„ˆë›°ê¸° |
| `--no-save` | - | - | ê²°ê³¼ íŒŒì¼ ì €ì¥ ì•ˆí•¨ |

### Output Example

```
============================================================
                    ğŸ“Š RAG ì‹œìŠ¤í…œ í‰ê°€ ê²°ê³¼
============================================================

ğŸ“Œ ê²€ìƒ‰ í’ˆì§ˆ (Retrieval)
------------------------------------------------------------
  â€¢ í‰ê·  ì§ì—…êµ° ì¼ì¹˜ìœ¨: 30.0%
  â€¢ í‰ê·  ê²½ë ¥ ì¼ì¹˜ìœ¨: 46.7%
  â€¢ í‰ê·  ê²€ìƒ‰ ì‹œê°„: 21.3ms

ğŸ“Œ ìƒì„± í’ˆì§ˆ (Generation)
------------------------------------------------------------
  â€¢ í‰ê·  ì‘ë‹µ ê¸¸ì´: 76ì
  â€¢ í‰ê·  ìƒì„± ì‹œê°„: 495.2ms
  â€¢ í•œêµ­ì–´ ì‘ë‹µ ë¹„ìœ¨: 100.0%
  â€¢ ì§ˆë¬¸ í˜•ì‹ ë¹„ìœ¨: 90.0%

ğŸ“Œ ì¢…í•© í‰ê°€
------------------------------------------------------------
  â€¢ ê²€ìƒ‰ í’ˆì§ˆ: ë³´í†µ
  â€¢ ìƒì„± í’ˆì§ˆ: ì–‘í˜¸
```

### Test Cases

20ê°œì˜ ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í¬í•¨:

| ì§ì—…êµ° | ê²½ë ¥ | ì˜ˆì‹œ ì¿¼ë¦¬ |
|--------|------|----------|
| ICT | EXPERIENCED | "ì €ëŠ” 10ë…„ê°„ ë°±ì—”ë“œ ê°œë°œì„ í•´ì™”ìŠµë‹ˆë‹¤..." |
| ICT | NEW | "ì»´í“¨í„°ê³µí•™ì„ ì „ê³µí•˜ê³  ì¡¸ì—… ì˜ˆì •ì…ë‹ˆë‹¤..." |
| BM | EXPERIENCED | "ì €ëŠ” 5ë…„ê°„ í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €ë¡œ ì¼í–ˆìŠµë‹ˆë‹¤..." |
| SM | NEW | "ë§ˆì¼€íŒ…ì„ ì „ê³µí–ˆê³ , ì¸í„´ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤..." |
| RND | EXPERIENCED | "10ë…„ê°„ ì—°êµ¬ê°œë°œ ë¶„ì•¼ì—ì„œ íŠ¹í—ˆë¥¼ ëƒˆìŠµë‹ˆë‹¤..." |

### Results Storage

```
server/rag/evaluation_results/
â””â”€â”€ evaluation_YYYYMMDD_HHMMSS.json
```

```json
{
  "timestamp": "2024-12-11T12:13:10",
  "config": {
    "num_samples": 10,
    "k": 3,
    "model": "llama-3.3-70b-versatile"
  },
  "summary": {
    "retrieval": {
      "avg_occupation_match": 0.30,
      "avg_experience_match": 0.467
    },
    "generation": {
      "korean_rate": 1.0,
      "question_format_rate": 0.9
    }
  },
  "retrieval_results": [...],
  "generation_results": [...]
}
```
